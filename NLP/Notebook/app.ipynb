{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c2f2a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "./document_rh.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \".\"\n",
    "\n",
    "file_path = os.path.join(base_dir,\"document_rh.txt\")\n",
    "\n",
    "print(base_dir)\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2b105b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre du poste : Analyste RH  \n",
      "Description : Nous recherchons un(e) Analyste RH pour rejoindre notre √©quipe dynamique.  \n",
      "Responsabilit√©s :  \n",
      "- Participer au recrutement des talents  \n",
      "- G√©rer les donn√©es RH dans notre SIRH  \n",
      "- Analyser les indicateurs RH (absent√©isme, turnover, etc.)  \n",
      "Profil :  \n",
      "- Bac +5 en Ressources Humaines ou √©quivalent  \n",
      "- Ma√Ætrise d'Excel et outils d‚Äôanalyse  \n",
      "- Esprit d‚Äô√©quipe et sens de l‚Äôorganisation  \n",
      "\n",
      "---\n",
      "\n",
      "Titre du poste : Responsable Formation  \n",
      "Description : Vous se\n"
     ]
    }
   ],
   "source": [
    "with open(file_path,\"r\",encoding=\"utf-8\") as f :\n",
    "    texte = f.read()\n",
    "\n",
    "print(texte[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nettoyage textuel automatique\n",
    "#suppression ponctuation\n",
    "#passag en minuscules\n",
    "#suppression des mots vide (stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7776c8",
   "metadata": {},
   "source": [
    "pip install nltk\n",
    "python -m nltk.downloader stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a6a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['titre', 'poste', 'analyste', 'rh', 'description', 'recherchons', 'analyste', 'rh', 'rejoindre', '√©quipe', 'dynamique', 'responsabilit√©s', 'participer', 'recrutement', 'talents', 'g√©rer', 'donn√©es', 'rh', 'sirh', 'analyser', 'indicateurs', 'rh', 'absent√©isme', 'turnover', 'etc', 'profil', 'bac', '5', 'ressources', 'humaines', '√©quivalent', 'ma√Ætrise', 'dexcel', 'outils', 'danalyse', 'esprit', 'd√©quipe', 'sens', 'lorganisation', 'titre', 'poste', 'responsable', 'formation', 'description', 'charge', 'strat√©gie', 'formation', 'lentreprise', 'missions', 'identifier', 'besoins', 'comp√©tences', '√©laborer', 'suivre', 'plan', 'formation', '√©valuer', 'lefficacit√©', 'actions', 'formation', 'comp√©tences', 'solides', 'comp√©tences', 'ing√©nierie', 'formation', 'connaissance', 'cpf', 'opco', 'bonne', 'communication', 'p√©dagogie']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "texte = texte.lower() \n",
    "texte = re.sub(r'[^\\w\\s]', '', texte)\n",
    "\n",
    "#tokenisation simple\n",
    "\n",
    "mots = texte.split()\n",
    "\n",
    "mots_utiles = [mot for mot in mots if mot not in stopwords.words('french')]\n",
    "\n",
    "print(mots_utiles[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc77b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('de', 7), ('formation', 5), ('rh', 4), ('en', 4), ('et', 4), ('du', 3), ('les', 3), ('comp√©tences', 3), ('titre', 2), ('poste', 2), ('analyste', 2), ('description', 2), ('notre', 2), ('des', 2), ('nous', 1), ('recherchons', 1), ('une', 1), ('pour', 1), ('rejoindre', 1), ('√©quipe', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ibrahima/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "tokens = nltk.word_tokenize(texte.lower()) #minuscule + tokenisation\n",
    "\n",
    "freq = Counter(tokens)\n",
    "\n",
    "#top 20\n",
    "\n",
    "print(freq.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aaa7fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les ‚Üí le\n",
      "√©tudiants ‚Üí √©tudiant\n",
      "√©tudiaient ‚Üí √©tudier\n",
      "s√©rieusement ‚Üí s√©rieusement\n",
      "et ‚Üí et\n",
      "leurs ‚Üí leur\n",
      "responsabilit√©s ‚Üí responsabilit√©\n",
      "√©taient ‚Üí √™tre\n",
      "importantes ‚Üí important\n",
      ". ‚Üí .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Charger le mod√®le SpaCy en fran√ßais\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Exemple de texte\n",
    "texte = \"Les √©tudiants √©tudiaient s√©rieusement et leurs responsabilit√©s √©taient importantes.\"\n",
    "\n",
    "# Traitement du texte\n",
    "doc = nlp(texte)\n",
    "\n",
    "# Afficher les lemmes\n",
    "for token in doc:\n",
    "    print(f\"{token.text} ‚Üí {token.lemma_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e6f22",
   "metadata": {},
   "source": [
    "TF-IDF et comparaison entre textes\n",
    "üéØ Objectif :\n",
    "\n",
    "    Convertir un ou plusieurs textes en vecteurs num√©riques (TF-IDF)\n",
    "\n",
    "    Comprendre ce que signifient ces vecteurs\n",
    "\n",
    "    Pr√©parer la base pour comparer, classer, ou entra√Æner un mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb6cbc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mots :  ['analyser' 'analyste' 'besoins' 'comp√©tences' 'de' 'd√©finit' 'en' 'et'\n",
      " 'formation' 'indicateurs' 'la' 'le' 'les' 'nous' 'pour' 'recherchons'\n",
      " 'responsable' 'rh' 'strat√©gie' 'un']\n",
      "[[0.29480389 0.29480389 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.29480389 0.         0.\n",
      "  0.2097554  0.29480389 0.29480389 0.29480389 0.         0.58960778\n",
      "  0.         0.29480389]\n",
      " [0.         0.         0.26255634 0.26255634 0.26255634 0.26255634\n",
      "  0.26255634 0.26255634 0.52511268 0.         0.26255634 0.26255634\n",
      "  0.186811   0.         0.         0.         0.26255634 0.\n",
      "  0.26255634 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "textes = [\n",
    "    \"Nous recherchons un analyste RH pour analyser les indicateurs RH.\",\n",
    "    \"Le responsable formation d√©finit la strat√©gie de formation et les besoins en comp√©tences.\"\n",
    "]\n",
    "\n",
    "#initialisation du vectorizer tf-idf\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#transformer les texte\n",
    "\n",
    "X = vectorizer.fit_transform(textes)\n",
    "\n",
    "#afficher les mot retenues (features)\n",
    "\n",
    "print(\"mots : \",vectorizer.get_feature_names_out())\n",
    "\n",
    "#afficher la matrice tf-idf\n",
    "\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reprise avec mon texte de d√©part via pipeline complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture du texte\n",
    "import os\n",
    "chemin_global = \".\"\n",
    "chemin_fichier = os.path.join(chemin_global,\"document_rh.txt\")\n",
    "with open(chemin_fichier,\"r\",encoding=\"utf-8\") as f :\n",
    "    texte_total = f.read()\n",
    "print(texte_total[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23d3475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer en minuscule le texte\n",
    "\n",
    "texte_total = texte_total.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bcd99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppresion des ponctuation\n",
    "import re\n",
    "texte_total = re.sub(r\"[^\\w\\s]\", \" \", texte_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de8f146f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ibrahima/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tokeniser\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokeniser = word_tokenize(texte_total,language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95234f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ibrahima/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#suppression des stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words_fr = stopwords.words(\"french\")\n",
    "tokens_utiles = [mot for mot in tokeniser if mot not in stop_words_fr and mot.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a73bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatiser avec spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "doc = nlp(\" \".join(tokens_utiles))\n",
    "lemmes = [mot.lemma_ for mot in doc if mot.lemma_ != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d6fd8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['titre',\n",
       " 'post',\n",
       " 'analyst',\n",
       " 'rh',\n",
       " 'description',\n",
       " 'recherchon',\n",
       " 'e',\n",
       " 'analyste',\n",
       " 'rh',\n",
       " 'rejoindre',\n",
       " '√©quipe',\n",
       " 'dynamique',\n",
       " 'responsabilit√©',\n",
       " 'participer',\n",
       " 'recrutemer',\n",
       " 'talent',\n",
       " 'g√©rer',\n",
       " 'donn√©e',\n",
       " 'rh',\n",
       " 'sirh',\n",
       " 'analyser',\n",
       " 'indicateur',\n",
       " 'rh',\n",
       " 'absent√©isme',\n",
       " 'turnover',\n",
       " 'etc',\n",
       " 'profil',\n",
       " 'bac',\n",
       " 'ressource',\n",
       " 'humain',\n",
       " '√©quivaloir',\n",
       " 'ma√Ætris',\n",
       " 'excel',\n",
       " 'outil',\n",
       " 'analyse',\n",
       " 'esprit',\n",
       " '√©quipe',\n",
       " 'sentir',\n",
       " 'organisation',\n",
       " 'titre',\n",
       " 'post',\n",
       " 'responsable',\n",
       " 'formation',\n",
       " 'description',\n",
       " 'charge',\n",
       " 'strat√©gie',\n",
       " 'formation',\n",
       " 'entreprendre',\n",
       " 'mission',\n",
       " 'identifier',\n",
       " 'besoin',\n",
       " 'comp√©tence',\n",
       " '√©laborer',\n",
       " 'suivre',\n",
       " 'plan',\n",
       " 'formation',\n",
       " '√©valuer',\n",
       " 'efficacit√©',\n",
       " 'action',\n",
       " 'formation',\n",
       " 'comp√©tence',\n",
       " 'solide',\n",
       " 'comp√©tence',\n",
       " 'ing√©nieri',\n",
       " 'formation',\n",
       " 'connaissance',\n",
       " 'cpf',\n",
       " 'opco',\n",
       " 'bon',\n",
       " 'communication',\n",
       " 'p√©dagogi']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc6f58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "texte_vect = \" \".join(lemmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "681b00d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titre post analyst rh description recherchon e analyste rh rejoindre √©quipe dynamique responsabilit√© participer recrutemer talent g√©rer donn√©e rh sirh analyser indicateur rh absent√©isme turnover etc profil bac ressource humain √©quivaloir ma√Ætris excel outil analyse esprit √©quipe sentir organisation titre post responsable formation description charge strat√©gie formation entreprendre mission identifier besoin comp√©tence √©laborer suivre plan formation √©valuer efficacit√© action formation comp√©tence solide comp√©tence ing√©nieri formation connaissance cpf opco bon communication p√©dagogi'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texte_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afb392f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absent√©isme' 'action' 'analyse' 'analyser' 'analyst' 'analyste' 'bac'\n",
      " 'besoin' 'bon' 'charge' 'communication' 'comp√©tence' 'connaissance' 'cpf'\n",
      " 'description' 'donn√©e' 'dynamique' 'efficacit√©' 'entreprendre' 'esprit'\n",
      " 'etc' 'excel' 'formation' 'g√©rer' 'humain' 'identifier' 'indicateur'\n",
      " 'ing√©nieri' 'ma√Ætris' 'mission' 'opco' 'organisation' 'outil'\n",
      " 'participer' 'plan' 'post' 'profil' 'p√©dagogi' 'recherchon' 'recrutemer'\n",
      " 'rejoindre' 'responsabilit√©' 'responsable' 'ressource' 'rh' 'sentir'\n",
      " 'sirh' 'solide' 'strat√©gie' 'suivre' 'talent' 'titre' 'turnover'\n",
      " '√©laborer' '√©quipe' '√©quivaloir' '√©valuer']\n",
      "[[0.09284767 0.09284767 0.09284767 0.09284767 0.09284767 0.09284767\n",
      "  0.09284767 0.09284767 0.09284767 0.09284767 0.09284767 0.27854301\n",
      "  0.09284767 0.09284767 0.18569534 0.09284767 0.09284767 0.09284767\n",
      "  0.09284767 0.09284767 0.09284767 0.09284767 0.46423835 0.09284767\n",
      "  0.09284767 0.09284767 0.09284767 0.09284767 0.09284767 0.09284767\n",
      "  0.09284767 0.09284767 0.09284767 0.09284767 0.09284767 0.18569534\n",
      "  0.09284767 0.09284767 0.09284767 0.09284767 0.09284767 0.09284767\n",
      "  0.09284767 0.09284767 0.37139068 0.09284767 0.09284767 0.09284767\n",
      "  0.09284767 0.09284767 0.09284767 0.18569534 0.09284767 0.09284767\n",
      "  0.18569534 0.09284767 0.09284767]]\n"
     ]
    }
   ],
   "source": [
    "#vectorisation qui consiste √† transformer les lemmes en vecteurs comprehensible par les mod√®les\n",
    "#pour vectorizer on utilise tfidvectorizer de scikit learn.feature_extraction.text \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform([texte_vect])\n",
    "\n",
    "#les mots retenus\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "#matrice TF-IDF\n",
    "\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4fdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
